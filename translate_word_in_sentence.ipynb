{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# from stardict import DictCsv\n",
    "from difflib import SequenceMatcher \n",
    "import itertools\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(source, token):\n",
    "\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    url = \"http://api.interpreter.caiyunai.com/v1/translator\"\n",
    "    \n",
    "    #WARNING, this token is a test token for new developers, and it should be replaced by your token\n",
    "#     token = \"3975l6lr5pcbvidl6jl2\"\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "            \"source\" : source, \n",
    "            \"trans_type\" : \"en2zh\",\n",
    "            \"request_id\" : \"demo\",\n",
    "            \"detect\": True,\n",
    "            }\n",
    "    \n",
    "    headers = {\n",
    "            'content-type': \"application/json\",\n",
    "            'x-authorization': \"token \" + token,\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "    return json.loads(response.text)['target']\n",
    "def longestSubstring(str1,str2): \n",
    "     # 两个字符串最长公共字符串\n",
    "     # initialize SequenceMatcher object with  \n",
    "     # input string \n",
    "    seqMatch = SequenceMatcher(None,str1,str2) \n",
    "  \n",
    "     # find match of longest sub-string \n",
    "     # output will be like Match(a=0, b=0, size=5) \n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "  \n",
    "     # print longest substring \n",
    "    if (match.size!=0): \n",
    "          return (str1[match.a: match.a + match.size])  \n",
    "    else: \n",
    "          return \"\"\n",
    "def get_trans(word_trans_from_dict, word_trans_from_translator, sentence_trans):\n",
    "    # 句子中的单词含义, 如果没有公共的, 就返回查到的词\n",
    "    match=longestSubstring(sentence_trans,word_trans_from_dict)\n",
    "    match=re.sub('[a-zA-Z0-9.\\n ]*',\"\",match) #只留下中文\n",
    "    exclude_list=[\"要\",\"着\",\"了\",\"过\",\"来\",\"的\",\"是\",\"说\",\"去\",\"到\",\"给\",\"做\",\"有\",\"看\",\"操\"]\n",
    "    if any(match == e for e in exclude_list):\n",
    "        match=\"\"\n",
    "    if match==\"\":\n",
    "        return re.sub('[a-zA-Z0-9.\\n ]*',\"\",word_trans_from_translator)\n",
    "    else:\n",
    "        return match\n",
    "def word_unknown(word_query, word_judge,exclude_word_list):\n",
    "    if not(word_query):\n",
    "        return False #查不到就算了\n",
    "    # check in exclude_word_list\n",
    "    if word_query['word'] in exclude_word_list:\n",
    "        return False\n",
    "    \n",
    "    # 是否认识?\n",
    "    include_tag=word_judge[\"include_tag\"] \n",
    "    exclude_tag=word_judge[\"exclude_tag\"]\n",
    "\n",
    "\n",
    "    collins_threshold=word_judge[\"collins_threshold\"]; collins_default=True\n",
    "    bnc_threshold=word_judge[\"bnc_threshold\"]; bnc_default=True\n",
    "    frq_threshold=word_judge[\"frq_threshold\"]; frq_default=True\n",
    "    \n",
    "    # check tag\n",
    "    include_list=include_tag.lower().split()\n",
    "    exclude_list=exclude_tag.lower().split()\n",
    "    if word_query['tag']: # 如果该单词有tag标记\n",
    "        word_tag=word_query['tag'] \n",
    "        tag_chk=(not(any(e in word_tag for e in exclude_list)) \n",
    "                 and \n",
    "                 any(i in word_tag for i in include_list))    \n",
    "    else:\n",
    "        tag_chk=True  #如果该单词没有tag标记, 默认为\n",
    "    \n",
    "    # check collins\n",
    "    collins_chk = (word_query['collins']<=collins_threshold) if word_query['collins']>=0 else collins_default\n",
    "    \n",
    "    # check bnc\n",
    "    bnc_chk=(word_query['bnc']>=bnc_threshold) if word_query['bnc']>0 else bnc_default\n",
    "    \n",
    "    # check frq\n",
    "    frq_chk=(word_query['frq']>=frq_threshold) if word_query['bnc']>0 else frq_default\n",
    "    \n",
    "    # check word length\n",
    "    length_chk=len(word_query['word']) >= word_judge['word_length']\n",
    "    \n",
    "\n",
    "    return ((tag_chk+collins_chk+bnc_chk+frq_chk) >=3 or length_chk)\n",
    "def add_trans_to_sentence(s, sdict, token, word_judge, exclude_word_list, filter_word=True):\n",
    "    sentence=s.replace(\"\\\\N\", \" \").replace(\"\\n\", \" \").replace(\".\",\" \").replace(\",\", \" \")\n",
    "    words=sentence.split()\n",
    "    words_to_trans={}\n",
    "    for word in words:\n",
    "        word_query=sdict.query(word) if sdict.query(word) else sdict.query('unknown')   \n",
    "        if filter_word:\n",
    "            if word_unknown(word_query,word_judge,exclude_word_list):\n",
    "                words_to_trans[word]=word_query['translation']\n",
    "        else:\n",
    "            words_to_trans[word]=word_query['translation']\n",
    "    if words_to_trans: # if words_to_trans is not empty\n",
    "        to_trans_list=[[sentence], words_to_trans.keys()]\n",
    "        to_trans_list=list(itertools.chain(*to_trans_list))\n",
    "        trans=translate(to_trans_list,token)\n",
    "        sentence_trans=trans[0]\n",
    "        word_with_trans={}\n",
    "        for idx, word in enumerate(words_to_trans.keys()):\n",
    "            word_trans=trans[idx+1]\n",
    "            word_with_trans[word]=get_trans(words_to_trans[word], word_trans, sentence_trans)\n",
    "        for (word, meaning) in word_with_trans.items():\n",
    "            meaning=word+\"(\"+meaning+\")\"\n",
    "            s=s[0:s.find(word)]+meaning+s[(s.find(word)+len(word)):]\n",
    "    return s, list(words_to_trans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
