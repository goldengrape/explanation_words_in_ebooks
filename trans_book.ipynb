{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate_word_in_sentence import translate, get_trans, word_unknown, add_trans_to_sentence\n",
    "import re\n",
    "from stardict import DictCsv\n",
    "from difflib import SequenceMatcher \n",
    "import itertools\n",
    "import string\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_book(epub_filename, output_filename, word_judge, dict_filename, token_filename):\n",
    "    with open(token_filename, 'r') as f:\n",
    "        token=f.read()\n",
    "    sdict=DictCsv(dict_filename)\n",
    "    \n",
    "    try:\n",
    "        with open(word_judge['exclude_word_filename'], 'r') as f:\n",
    "            exclude_word_list=f.read()\n",
    "    except:\n",
    "        exclude_word_list=\"\"\n",
    "\n",
    "    book = epub.read_epub(epub_filename)\n",
    "\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            raw_text=item.get_body_content().decode('utf-8')\n",
    "            soup = BeautifulSoup(raw_text, 'lxml')\n",
    "            for p in soup.find_all(\"p\"):\n",
    "                for idx, s in enumerate( p.contents):\n",
    "                    if type(s)==bs4.element.NavigableString:\n",
    "                        try:\n",
    "                            s_t, w_t=add_trans_to_sentence(s, sdict, token, word_judge, exclude_word_list)\n",
    "                            p.contents[idx].replace_with(s_t);\n",
    "                        except:\n",
    "                            pass\n",
    "            item.content=str(soup.body).replace(\"<body>\",\"\").replace(\"</body>\",\"\") #非常难看但有效\n",
    "    epub.write_epub(output_filename, book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser(description='Process subtitle.')\n",
    "    parser.add_argument('-i', '--input', dest=\"input_filename\", help=\"需要处理的epub电子书\")\n",
    "    parser.add_argument('-o', '--output', dest=\"output_filename\", help='输出文件名')\n",
    "    parser.add_argument('-include', nargs='?', dest=\"include_tag\", type=str,\n",
    "                        help='生词的定义: 包含哪些标记, 用空格隔开, 例如 cet6 toelf gre ielts',\n",
    "                       default=\"cet6 gre ielts\")\n",
    "    parser.add_argument('-exclude', nargs='?', dest='exclude_tag', type=str,\n",
    "                        help='生词的定义: 除外哪些标记, 用空格隔开, 例如 zk gk cet4',\n",
    "                       default=\"zk gk cet4\")\n",
    "    parser.add_argument('-collins', nargs='?',dest='collins_threshold', type=int, \n",
    "                        help='collins星级', default=2)\n",
    "    parser.add_argument('-bnc', nargs='?', dest='bnc_threshold', type=int,\n",
    "                       help='英国国家语料库词频顺序bnc, 越大越难', default=5000)\n",
    "    parser.add_argument('-frq', nargs='?', dest='frq_threshold', type=int,\n",
    "                       help='当代语料库词频顺序frq, 越大越难', default=5000)\n",
    "    parser.add_argument('-e', '--exclude_word', nargs='?', dest='exclude_word_filename', \n",
    "                        type=str, help='需要排除的单词列表, txt文件, 每行一个单词', \n",
    "                        default=\"exclude_word_list.txt\")\n",
    "    parser.add_argument('-l', '--word_length', nargs='?', dest='word_length', \n",
    "                        type=int, help='一定长度以上的单词将默认提示', \n",
    "                        default=10)\n",
    "\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    word_judge={}\n",
    "    word_judge[\"include_tag\"]=args.include_tag \n",
    "    word_judge[\"exclude_tag\"]=args.exclude_tag \n",
    "    word_judge[\"collins_threshold\"]=args.collins_threshold \n",
    "    word_judge[\"bnc_threshold\"]=args.bnc_threshold \n",
    "    word_judge['frq_threshold']=args.frq_threshold \n",
    "    word_judge['exclude_word_filename']=args.exclude_word_filename\n",
    "    word_judge['word_length']=args.word_length\n",
    "    \n",
    "    process_book(args.input_filename, \n",
    "                 args.output_filename, \n",
    "                 word_judge,\n",
    "                dict_filename=\"ecdict.csv\", \n",
    "                token_filename='token.txt'\n",
    "               )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
